{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/nvidia-llm-colab/blob/main/nemo_2b_bf16_tp1.ipynb)"
   ]
  },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!apt -y install -qq aria2\n",
        "!npm install -g localtunnel\n",
        "!git clone https://huggingface.co/camenduru/apex\n",
        "# !git clone https://github.com/NVIDIA/apex.git\n",
        "%cd /content/apex\n",
        "# !git checkout 03c9d80ed54c0eaa5b581bf42ceca3162f085327\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" --global-option=\"--fast_layer_norm\" --global-option=\"--distributed_adam\" --global-option=\"--deprecated_fused_adam\" ./\n",
        "!pip install nemo_toolkit['nlp']==1.17.0\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/NVIDIA/NeMo.git \n",
        "%cd /content/NeMo/examples/nlp/language_modeling\n",
        "!git checkout v1.17.0\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/nvidia/GPT-2B-001/resolve/main/GPT-2B-001_bf16_tp1.nemo -d /content/NeMo/examples/nlp/language_modeling -o nemo_2b_bf16_tp1.nemo\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "def iframe_thread(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex(('127.0.0.1', port))\n",
        "        if result == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "    p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "    for line in p.stdout:\n",
        "        print(line.decode(), end='')\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(5555,)).start()\n",
        "\n",
        "!python megatron_gpt_eval.py trainer.precision=bf16 gpt_model_file=nemo_2b_bf16_tp1.nemo server=True tensor_model_parallel_size=1 trainer.devices=1"
      ],
      "metadata": {
        "id": "8fLY9_xXzN9a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}